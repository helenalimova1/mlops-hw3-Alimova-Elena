

Этот проект представляет собой ML-сервис, который использует gRPC-сервер для выполнения предсказаний. Он разработан с использованием фреймворка gRPC-сервер и упакован в контейнер Docker. Основная цель данного проекта — продемонстрировать стратегию развертывания ML-сервиса с использованием подходов Blue-Green и Canary Deployment.



Зачем это сделано?

• Гибкость: Позволяет легко переключаться между версиями модели без прерывания работы сервиса.

• Надежность: Обеспечивает возможность быстрого отката к предыдущей версии в случае возникновения ошибок.

• Автоматизация: Использование CI/CD для автоматического развертывания и тестирования новых версий модели.



Как запустить:



Предварительные требования:

• Установленный Docker

• Установленный Docker Compose

• Установленный Python 3.8 или выше



Шаги по запуску



1\. Клонируйте репозиторий:



&nbsp;  https://github.com/helenalimova1/mlops-hw3-Alimova-Elena.git

&nbsp;  

2. Сборка Docker:

docker build -t grpc-ml-service .



Запуск Docker: docker run -p 50051:50051 grpc-ml-service   



Стратегия развертывания:



• Blue-Green Deployment: Создаются две версии сервиса (Blue и Green). Вы можете переключаться между ними, изменяя конфигурацию балансировщика.

Запуск и проверка:



docker compose -f docker-compose.blue.yml up -d

docker compose -f docker-compose.green.yml up -d



• Canary Deployment: Новая версия сервиса (канарейка) запускается параллельно со старой, и постепенно увеличивается доля трафика, направляемого на новую версию.



Настройка CI/CD

Для автоматизации развертывания используйте GitHub Actions. Настройте файл .github/workflows/deploy.yml в соответствии с вашими требованиями и добавьте необходимые секреты в настройки репозитория.



Заключение

Этот проект демонстрирует основные принципы развертывания ML-сервиса с использованием Docker и gRPC. Следуя приведенным инструкциям, вы сможете запустить свой собственный ML-сервис и ознакомиться с методами управления версиями и развертыванием.

